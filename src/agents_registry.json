{
    "default-LLM.py": {
        "function": "Default LLM agent",
        "required_inputs": [
            {
                "variable": "task_definition",
                "description": "The description of the task to be solved by the LLM agent."
            }
        ],
        "output": "text result of the agent's action",
        "class": "DefaultLlmAgent",
        "models": [
            {
                "name": "gpt-4o-mini",
                "hyperparameters": {
                    "temperature": [
                        0,
                        1
                    ],
                    "api_version": "2023-03-15-preview",
                    "deployment_name": "gpt-4o-mini"
                }
            },
            {
                "name": "Phi-4-mini-instruct",
                "hyperparameters": {
                    "temperature": [
                        0,
                        1
                    ],
                    "top_p": [
                        0.1,
                        1
                    ],
                    "presence_penalty": [
                        -2,
                        2
                    ],
                    "frequency_penalty": [
                        -1,
                        1
                    ]
                }
            },
            {
                "name": "DeepSeek-R1",
                "hyperparameters": {}
            }
        ]
    },
    "multimodal_agents.py": {
        "function": "Interpret a combination of images and textual prompts",
        "required_inputs": [
            {
                "variable": "image_path",
                "description": "The path or file of the image to be analyzed."
            },
            {
                "variable": "text_input",
                "description": "The path, file or text to be analyzed."
            }
        ],
        "output": "textual interpretation of image + prompt",
        "class": "MultimodalTaskAgent",
        "models": [
            {
                "name": "Phi-3.5-vision-instruct",
                "hyperparameters": {
                    "temperature": [
                        0,
                        1
                    ]
                }
            },
            {
                "name": "Llama-3.2-11B-Vision-Instruct",
                "hyperparameters": {
                    "temperature": [
                        0,
                        1
                    ]
                }
            },
            {
                "name": "gpt-4o",
                "hyperparameters": {
                    "temperature": [
                        0,
                        1
                    ]
                }
            },
            {
                "name": "Phi-4-multimodal-instruct",
                "hyperparameters": {
                    "temperature": [
                        0,
                        1
                    ]
                }
            }
        ]
    },
    "natural_language_agent.py": {
        "function": "Interpret and resolve language-based tasks (e.g., summarization, classification, Q&A)",
        "required_inputs": [
            {
                "variable": "task_definition",
                "description": "The description of the task to be solved by the LLM agent."
            },
            {
                "variable": "text_input",
                "description": "The path, file or text to be analyzed."
            }
        ],
        "output": "textual response (summary, classification, etc.)",
        "class": "LanguageTaskAgent",
        "models": [
            {
                "name": "gpt-4o-mini",
                "hyperparameters": {
                    "temperature": [
                        0.0,
                        1.0
                    ],
                    "api_version": "2023-03-15-preview",
                    "deployment_name": "gpt-4o-mini"
                }
            },
            {
                "name": "Phi-4-mini-instruct",
                "hyperparameters": {
                    "temperature": [
                        0.0,
                        1.0
                    ],
                    "top_p": [
                        0.1,
                        1.0
                    ],
                    "presence_penalty": [
                        -2.0,
                        2.0
                    ],
                    "frequency_penalty": [
                        -1.0,
                        1.0
                    ]
                }
            },
            {
                "name": "Llama-3.3-70B-Instruct",
                "hyperparameters": {
                    "temperature": [
                        0.0,
                        1.0
                    ],
                    "top_p": [
                        0.1,
                        1.0
                    ],
                    "presence_penalty": [
                        -2.0,
                        2.0
                    ],
                    "frequency_penalty": [
                        -1.0,
                        1.0
                    ]
                }
            },
            {
                "name": "DeepSeek-R1",
                "hyperparameters": {}
            },
            {
                "name": "qwen/qwen2.5-coder-32b-instruct",
                "hyperparameters": {
                    "temperature": [
                        0.0,
                        1.0
                    ],
                    "top_p": [
                        0.1,
                        1.0
                    ]
                }
            }
        ]
    },
    "numerical_logit_agent.py": {
        "function": "Perform structured reasoning on tabular or numerical inputs",
        "required_inputs": [
            {
                "variable": "structured_data",
                "description": "The structured data to be processed."
            }
        ],
        "output": "reasoned textual answer or numerical prediction",
        "class": "NumericReasoningAgent",
        "models": [
            {
                "name": "gpt-4o-mini",
                "hyperparameters": {
                    "temperature": [
                        0.0,
                        0.7
                    ]
                }
            },
            {
                "name": "DeepSeek-R1",
                "hyperparameters": {
                    "temperature": [
                        0.0,
                        0.7
                    ]
                }
            }
        ]
    },
    "object_detection_agent.py": {
        "function": "Detect objects in an image",
        "required_inputs": [
            {
                "variable": "image_path",
                "description": "The path or file of the image to be analyzed."
            }
        ],
        "output": "list of detected objects",
        "class": "ObjectDetectionAgent",
        "models": [
            {
                "name": "yolo11n",
                "hyperparameters": {
                    "classes": []
                }
            },
            {
                "name": "yolov8n",
                "hyperparameters": {
                    "classes": []
                }
            },
            {
                "name": "resnet50",
                "hyperparameters": {
                    "weights": []
                }
            },
            {
                "name": "Llama-3.2-11B-Vision-Instruct",
                "hyperparameters": {
                    "temperature": [
                        0,
                        1
                    ]
                }
            },
            {
                "name": "Phi-3.5-vision-instruct",
                "hyperparameters": {
                    "temperature": [
                        0,
                        1
                    ]
                }
            }
        ]
    }
}